好OK，我们开始上课呃，今天是我们的呃VIP大模型的第一节课。那我们今天晚上的核心内容呢，是给大家介绍我们大模型的第一个平台hagen face。呃，先看一下我们今晚的核心内容啊。呃，今晚内容的话呢，相对来说不是特别的复杂，主要是让大家熟悉这么几个东西，第一个就是呃，你们所学的这个大模型到底是个什么东西？我们待会给大家做个介绍。第二点的话呢，

我们今后的这个课程中哈，包括大家以后如果进了这一行。我们所需要用到的所有的这个AI大模型。基本上都是从两个平台上面来获取。第一个平台就是hagen face。这个是非常重要的一个平台。因为目前来讲，全球几乎是所有的AI大模型你都可以从哈根费斯上面去找到啊，当然这个平台的话呢，也存在一定的缺陷。就是对于我们国内啊，不是特别的友好啊，因为我们这个网络受到限制，所以说如果我们要使用haagen face的话呢？我们得通过一些其他的方法啊，

能够科学上网，你才能够上得了这个平台，那么我。我们国内呢，一般来讲，我们首推的平台其实是后面要给大家讲的，另外一个平台叫model scope魔塔社区。啊，那是阿里社区推的一个平台，那个平台上面的优势呢，就是我们从魔塔社区上面去获取达摩群的速度要快一些。呃，但是魔塔社区上面的模型是没有hang face这么全的，所以说我们在这边的话呢，首先先给大家讲这个hang face啊，

因为这个平台非常重要。啊，这个平台非常重要，包括我们后面的大模型的一些推理的方法就是hagen face也是其中之一啊。好，那么先来看一下啊，我们今晚重点在于对于这个平台的一些使用和了解。啊，对这个平台使用很了解，第一点就是教大家怎么去使用这个hang feed这个平台，以及怎么在hang feed平台上面去。下载我们所需要的一些这个大模型呃，其二呢hang face，它跟大家前面应该前置课里面哈有调用过一些这个。open AI的一些aap I去使用一些大模型，

那hang face跟你们前面所用的open AI API那个用法一样，它也提供了API的模型调用。但这个东西我说句实话啊。我们只给大家讲一下它的使用方法，你们知道这个哈根费斯平台，它支持API调用的就行了呃，原因呢？就是说这个东西在。从实用性上面来讲，基本没有什么实用性啊，就因为hank face是国外的，所以说它的网络受到很多限制啊，我们一般不推荐用这个。呃API的形式来调用这个大模型啊，大模型这个东西核心都是做私有化部署啊。

好那么其次呢？汉克菲这个平台，它里面有几个组件啊？就是这个这几个组件主要是帮助我们去本地化调用它的这个模型的。啊，那么核心就两个，一个是transformer，另外一个是个dataset。好，那么最后的话呢？我们会给大家介绍一下，就是今晚今晚的这个实操部分呢嗯，不是特别多，一个是API的调用，另外一个就是我们教大家怎么把？

hag face上面的模型下到我们的本地电脑上面来做调用啊。好，那么我们先给大家介绍一些这个基础的知识啊。呃，先介绍几个概念，第一个就是大家现在所学的这门课啊。叫这个。AI大模型。好AI大模型，那么我先要给大家梳理一下这个基本概念就是什么是大模型对吧？呃，第一个问题，你们要搞明白什么是大模型？什么是大模型？呃，

这个概念其实很简单，大模型它来源于AI模型啊AI模型，那么就比我们以前传统的AI模型要大一些。简单来理解。简单来理解。啊来。理解就是。比较参数量参数量。参数量比较多，比较多啊诶。参数量比较多的AI模型。这就是我们的这个大模型啊，这个就属于我们的大模型，这个有多少呢？这个参数量有多少呢？

我们一般来讲对现在的这个大模型的。定义是这样的，参数量在十亿以上。啊参数量参数量参数参数量。在十亿以上啊。十亿。呃，就十亿个参数以上。呃，十亿以上。参数量在十亿以上的AI模型，我们把它叫做大模型，那么如果说这个AI模型的参数量在十亿以下呢？我们一般把它称之为AI小模型。啊，

小模型好，那么这个十亿啊，现在其实有个单位啊，有个单位我们一般模型后面大家可以看到几b几b哈。实意就是1b啊1b啊，one buildings。好，这个是基本概念，要搞明白，所以你先要搞明白什么是大模型，就是参数量比较多的AI模型啊AI模型。所以这里面有一个最核心的概念，就是说AI模型是个什么东西，对吧啊？AI模型是个什么东西？

什么是AI模型？什么是AI模型？好，这个你们也要理解呃，因为在座的各位同学哈，应该你们之前从事软件开发的同学比较多。啊，所以我在一开始要给大家明确一个概念。AI大模型开发，它跟你们以前做程序不一样。呃，这一点要注意啊，我们以前做程序开发呢其实。呃，对于一个程序员来讲哈，

它的基本要求实际上是比较低的啊，换句话来讲，比如说我做JAVA开发对吧？那么我需要掌握，就是目前这个JAVA行业里面它所用的一些软件框架的API调用就行了。当然AI模型，它其实跟你写代码没有多大的关系啊AI模型跟你写代码其实没有多大的关系，它的核心是什么？它的核心是一个数学模型。它的核心是个数学模型。好啊，这我简单定义下这个概念AI模型AI模型也称之为也称为。啊，也称为我们的人工神经网络。这一点要注意，

人工神经网络本质上本质上是用来。做矩阵运算的。啊，做矩阵运算的啊，这一点要记住，所以我们现在所谓的AI AI，它是干什么的？它是做数据数据运算的。它是对数据做处理的一个模型，明白了吗？它是对数据做处理的一个模型，所以说这个东西它存在一定的不确定性。啊，注意。它存在一定的不确定性，

它不像我们以前写代码，我调这一行API，它出来就是这么一个结果AI模型，不是的AI模型，不是的，它存在一定的不确定性，就是我们所谓的随机性。这一点你们要特别注意一下啊，所以它不是说我一行API就调出来就一定是这种结果啊，尤其是我们后面进行到一些这个项目实操的时候。那么，很多同学在自己做实验的时候，你会发现它跟跑出来的这个结果跟我们课堂上面结果可能会不一致哈，这是正常的，我说一下啊，

因为我们这个行业有自己的这个结果的评估方法。好，所以说把这两个基础的点记住啊，把这两个基础点记住啊。OK好，然后呢？跟我们相关的第三个点就是我们这个课啊，这个AI大模型。大模型现在其实传统意义上的大模型，它分为两种。AI大模型。如何分类。这一点要注意一下，目前分为两类。目前分为两类啊，

两类，第一类是。第一类是。呃，第一类是什么东西呢？我用a来记啊。第一类就是我们这门课所学的叫自然语大模型。呃，自然语句。呃自然语义大模型第二类呢？就是我们现阶段大家可能看到的其他的一些大模型，我们叫多模态大模型。啊，这两个东西要注意一下，目前的这个大模型，

我们其实把它分为两种，一个叫自然语义大模型，另外一个就是我们的这个多模态大模型。好，我先说一下这个大模型的价值在什么地方？其实大模型最具价值的地方就在于这个自然语言，大模型这个部分。啊，就在于自然语义大模型这个部分大模型是如何出现的呢？好，我说我这把这加了这个东西是重点啊。核心目前目前。的这个AI大模型。的核心技术。是自然语义大模型。

呃自然语义大模型。目前的AI核心技术其实是自然语言模型，为什么说这个玩意儿是核心呢？呃，因为是这样的，我简单说一下，大模型是怎么怎么出现的哈？实际上，在一九年之前，我们的这个AI这个行业。它有个定理。有个什么定理呢AI这个行业以前叫深度学习。可能有同学听过这个词啊。呃，什么叫深度学习呢？

就是说我们研究的是个人工神经网络。这个行业很早之前就发现一个定理，我们所设计的这个人工神经网络越大。这个模型的效果就越好。啊，这个模型的效果越好，所以说以前啊，我们做AI这一行主要研究什么东西，主要研究深层次的人工神经网络的学习方法。用来解决现实生活中比较复杂的问题。当时，二零一九年呢open AI这家公司。做了一件事啊，他把这个模型搞得非常的大，有多大呢？

这个模型的参数超过了十亿。啊，这个模型的参数超过了十亿，然后呢，它就发现了一个很有意思的现象啊，就是我们以前加深人工神经网络哈。它的模型的参数。比如，我们以横轴代表模型的参数，纵轴代表这个模型的智能对吧？以前在十亿以下的时候的话呢，就是你增加参数量，增加参数量，这个模型的智能会有所提升。但它提升的话呢，

其实是一个比较平缓的提升的一个方向。但欧朋亚这家公司当时研究的时候，大家发现一个很有意思的地方，就在于我当模型的参数超过十亿以上的时候的话呢，这个智能会呈现一个指数级别的增长。啊，这个智能会呈呈现一个指数级别增长，就是它会变得非常的快，就是你超过十以上，你再增加一些这个参数，它的智能就完全是翻天覆地的一个变化了哈。我们把这个特征呢，叫做智能涌现啊，这个概念听一下啊，这个特征叫智能涌现，

有一篇论文是专门去研究这个东西的。好，那么从这儿就开始AI模型就分成了两个方向，一个叫大模型，一个叫小模型，我们把超过十亿参数以上的模型叫大模型。把十亿以内的参数叫小模型，那么这个大小的区别在什么地方呢？就是当你的参数超过十亿以上的时候，这个AI模型它能够对我们目前人类社会中的这个数据哈。有一种更加深层次的理解能力，就是我们所希望看到的智能。简单来理解，就是我们所希望在计算机上面看到的智能。是在这个大模型上面体现出来了啊，

这个概念要要搞明白哈，这个概念要搞明白哈，好，所以说早期我们训练出来的这个自然语义大模型哈，就是现在定义的这个大模型的核心，实际上就是自然语义大模型。就我们通过这种nip的方式，文本的形式啊，文本的形式让机器来理解我们人类社会中所表达的这个思想。啊，这个概念要记住啊，所以说现在的这个自然域大模型其实承担的是什么东西呢？承担的是AI的一个核心思想。AI的智能啊，这个要记住，

然后呢？刚刚上面这儿所提到的多模态，多模态是个什么意思？就是我们数据啊，它是多样性的数据是多样性的数据，有图像，有视频，有音频，对吧，有文本。那么，我们把所有的图像音频。图像音频，还有就是除了文本以外的这种数据表现形式叫做多模态，但是要注意这种多模态的模型，

它是基于什么基于自然语言大模型来发展的？啊，基于自然模语言大模型来发展的，所以说我们的自然语义大模型，它发展的呃就是自然语义大模型的效果要好的情况下呢，你的这个多模态的模型效果才会更好一些哈，简单说两个例子就是说。最早出现的是open AI的这个chart gpt，然后chart gpt出了应该是两个月到三个月吧，这个纹身图的模型就出来了，像MID junior stability fashion对吧？当时比较有名的。啊，那么这个是这个文本呃纹身图的这个模型出来之后呢？其实应该是到大半年啊，

隔了大半年，这个纹身视频就出来了是吧？所以它有一个顺序啊，为什么有一个顺序呢？因为多模态是基于自然域达模型的，这个概念要记住。啊，所以目前的这个大模型的核心实际上是自然语大模型这一块啊啊，我们的这个课程呢，也是围绕着自然语大模型的这个应用听清楚啊，我这说的是我们的课程是围绕着大自然语大模型的应用开发。来给大家展开做讲解的。所以还有一个点，各位要记住，我们不是开发大模型，

听清楚啊，我们这堂课不是开发大模型，我们这门课程呢，是教大家怎么用别人？提供好的赞誉大模型来做应用落地啊，来做应用开发是做业务流程这一块的啊，这个东西要区分清楚啊。好，这是课前的一些这个准备。给大家简单梳理一下这几个概念啊。啊，然后的话呢，接下来就进入到我们这个课程相关的一些内容了，那么了解了自然语义大模型的这些基本概念之后，我刚刚提到过了我们这门课程是教大家怎么去开发？

怎么去应用别人提供好的这个战略大模型来做我们自己的这个业务啊，来做我们自己的业务落地。所以核心是什么？核心是我们得使用大模型啊，使用大模型目前。目前AI大模型的主流开源平台。恋爱大模型主流。开源平台。就两个。啊，就两个我们核心运用的就两个，一个是hagen face。啊hf一个是modo scope啊halcon face modelo scope啊。而简称一下哦OK，那么我们今天的话就先来学习这个什么haag on face啊，

先来学习haag on face呃，先说一下啊，haag on face这个课程的内容啊。我们在大家下去实操的时候要注意，你要上这个网的话，你得。翻墙啊，你得科学上网，所以我这边先开一下网络啊，不开网络的话，我们是上不去的，这个网这个网站。这个东西我不能给你们录啊，反正梯子的东西大家呃，自己下去想想办法，

或者你们可以完了在群里面进行一个交流哈。呃，我这只提一句，就是你们到时候用的这个代理啊。你得用美国的啊，不要用国内啊，代理不要用国内的，尽量是欧美，欧美这边啊，尽量是欧美这边。好呃，网络开好之后的话呢，我们来先看一下haa gnfi这个官网。呃哈根费斯啊哈根费斯。呃，

直接我建议是直接从bin里面去搜hang face。那么，大家看到的这个hang face点co就是它的官网啊，那它的logo是一张笑脸啊，是一张笑脸。好，我们点进去看一下这个平台。呃，这个平台是个什么东西啊？我简单做个介绍这个平台的话呢，你把它理解成是我们AI界的g type。啊aij的get up就可以了。就你可以从。哈根费上面去找到几乎是所有的AI的开源模型啊AI的开源模型，它是一个AI的开源社区啊。

好，我们看一下它官网上面一个介绍。介绍其实介绍的非常简单，这就是一个一个AI社区，面向于未来构建的一个什么AI社区。这个社区非常有意思啊，最早它是二零一九年的时候就已经推出了，但是二零一九年推出的时候的话呢，这个社区的结构比较简单，它上面只有自然语义模型。二零一九年，当时推出的时候只有自然语言模型，但是二零一九年过了半年之后啊，这个平台上面所推的模型就很全了。几乎是现在你你能够看到的所有的AI模型，

这上面都可以找得到啊，这上面都可以找得到啊，那么这个结构的话呢，我们下面没啥好看的啊，核心它的核心在上面这个部分。在这啊，这个平台里面提供了两个非常实用的东西。一个是models，就是我们所需要的模型全部在model里面，另外一个就是说我们的这个嗯。AI模型啊，如果大家作为上手学习的话呢，我们得用一些数据集来训练我们自己的模型啊，那么这个平台它也提供了一些开源的这个数据集。啊，

那么与此同时的话呢？它也提供了像这个社区交流的啊，还有像文档里面都有啊，但是这两个东西这个东西我觉得就没有必要，现在我们去看啊，没什么大的意义啊。然后的话呢，它是docs。这个文档其实目前hang face的文档给的也比较全啊，文档上面有关于它这个组件的一些详细用法的一些介绍。呃，这个东西的话呢，目前现阶段哈，我觉得大家没有必要特别的去去看啊，因为我们课程上面就会给大家去讲，

我们讲的东西就是人家这个文档上面所需要介绍的。当然，文档上面介绍的东西会更加繁琐一些啊，我们这个课程上面其实核心用到的就两个板块，一个是它的模型板块transformers。另外一个是它的数据板块dataset啊，这个我们待会会给大家介绍到啊。好，那么我先看第一个板块models，这个板块是对于我们来讲价值最大的。就是hang face平台上面目前提供了所有的这个AI模型，然后它对模型做了分类。啊，做了分类默认，第一个是按照任务来划分啊，

任务来划分，那么任务来划分，我们可以看到这里面有什么有多模态的，有视觉的，对吧？有自然语义的。啊，还有音频相关的啊，还有就是其他的一些这个强化学习相关的，还有其他的模型做好划分的，对吧？啊，你比如像这里面audio takes to takes。啊，然后image text to text对吧？

你点进去，比如说这个里面啊，我们点一个image text to text，它里面所有的模型全部都是什么？全部都是这个呃文，我就输入的是图像跟文本，然后输出的是什么文本？这所有模型都在里面哈，当然我们在这个课程里面，我们核心运核心用的是这个自然语义部分。啊，占用一部分。这样一部分的话呢，像现在的这个AI大模型哈，有一点要说一下，

它是基于transformer构建的。构建出来有两个部分。我们前期课程上会给大家讲这一块讲的比较细一些，它分为两个部分，第一个部分是做分类的。就是bert模型。呃，这个东西其实跟我们主流课程的关系不是特别的大，我们现在主流课程的这个大自然语大模型都是做生成的。啊，都做生成的啊，生成的其实是这一块啊text generation。好，这两个板块儿是比较关键的啊啊，这两个板块儿是比较关键的OK啊，

打个比方，比如说我们这儿搜搜一个这个文本生成对吧？文本生成你像文本生成里面现在比较著名的这个deeps排行第一。啊deep seek的r1模型啊，这是文本生成里面的，然后像国内里面现在有名列除了deep seek以外的话就是千万。啊，千万当然千万，目前的这个热度没有deep six这么高啊，排到后面去了，看到没有千万二点五啊code。啊，就是我们后面所需要用到的所有的模型，你都可以在这找得到啊呃，但是这个东西我到后面会详细说啊，

我们一般不建议，就是大家去下这种很大的模型。从哈格菲上面去下就不太好搞了。好，当然，你也可以直接去搜索啊搜索，比如说像这个千万啊一点五。呃，一点五对吧？你一搜它就出来了啊？啊，前文一点五版本有零点五b的，一点八b的，一点四b的，一点七呃，

这个7b的都有，那么目前最新的是二点五版本。二点五版本。二点五版本里面都有啊，我们随便点进去看一个吧。好比如说你想要这个，你想你想获取这个模型对吧？获取这个模型，获取这个模型的话呢？嗯，目前hank face平台上面它提供的方法就是用。呃，SDK啊，就我们通过代码来获取这个模型，这个我待会会给你们讲怎么去获取啊？

呃，哈弗这个平台呢？有一点做的比较好的，就是说。嗯，它提供了一些使用的接口方法，方法有有有接口有案例，但是这个案例是有些模型有有些模型没有啊，比如说。像这个千文一点八bch at啊，这上面它就没有直接给我们提供那个使在线的使用接口。好好，我们简单看一下啊。以这个模型为例的话呢，如果说你要去获取这个模型，

它下面应该是有方法的，看到没有啊？这有方法啊，第一步我们得安装。hagen face的transform平台，这个先不着急啊，我我待会会带着大家一起来装一下啊，装好平台之后的话呢，怎么来获取呢？你可以通过get get来获取。啊，你也可以可以通过它的这个什么呢？transformer就是haag face平台里面的这个SDK来进行获取。啊，两种方法都可以啊，

两种方法都可以好啊，那么获取完了之后，它下面会给我们使用案例，一般来讲hank face平台就是现在大于原模型平台，上面都会给到你这个模型，下下来之后怎么来下载，对吧？下来之后怎么来用的？啊，怎么来用的？它上面都会有一些示例啊。好，这儿我们先简单看一下吧嗯，然后模型里面的第二个类目里面它主要是提供了当前你需要下下载的这个千位一点八BC hart里面它所包含的文件结构啊。啊所包含的文件结构就这里面注意一下呃，

我们现在所谓的这个AI模型哈呃，常见的在哈根费斯上面，包括在魔塔社区上面，我们常见的这个格式叫做safety tensors啊。这是我们的模型，看到没有呃，这是模型的文件哈啊，模型文件你比如说这个模型文件，它分为两份啊，两份，第一份是二点四个GB，二点零四GB。第二份是一点六三个GB。好，然后这个community就是关于这个模型的一些社区交流哈啊，

这一块一般都是空的，没有什么太大的价值。好，这是模型内部啊，模型内部那么其他的一些模型里面的像这个hang face，它也提供了，它也提供了呃在线的使用接口啊，你比如说我们这儿。但是文本上面现在一般一般比较少啊，打个比方像这个纹身图，纹身图stable de fiction。啊stable diffusion。我记得是这个。你看啊，这个step diffusion里面它就提供了这个。

呃，使用的这个接口啊，使用接口你可以在这儿输入文本啊，我们在这儿就可以在线的进行测试了，当然它这个东西在测试的话呢需要。进行登录啊，需要进行登录。好，这是模型部分。啊models，部分models，部分大家先了解到这儿，我们待会儿大家来实操第二个部分就是dataset dataset的结构跟models结构非常类似。它同样的按照这个不同的这个结构啊，比如说语言对吧任务啊，

还有这个其他的一些授权对吧，其他一些方法。对模型，对这个数据集做了一个分类啊，对数据做了分类，然后我们我们可以看到这个数据分类，它有3d的3d视觉的有音频数据。啊，还有这个图像啊，文本等等呃，视频等等，这些数据集都有啊，都有，当然我们数据集的话呢，在这门课程里面哈，

核心用到其实是文本。啊，核心描述文本啊。好，那么我们这随便点开一个啊，给大家看一下。待会儿我们会带着大家一起来下载来获取，那么这就是一个文本数据啊，这是它数据的一个示例。啊，数据设定其实这个网站结构都比较简单，没有没有太多复杂的东西。好那么简单，了解这个结构之后的话呢，我们接下来带着各位来实操一下，

怎么来上手han k fai这个平台？呃，这边的话呢，我给大家简单做了一个这个。文档啊，大家下去之后按照我们的文档去实操就行了啊，关于ha g fai是是ha g fai这一块啊好，我们先来看一下它这个简单的一个介绍。haag face的话呢，它是一个提供了先进自然语言处理的工具平台，那么现在你们把它当成是我刚刚说过了，当成是一个呃AI界的git HUB就可以了。它上面的模型啊，核心是以transformer模型为主啊，这点要注意啊，

它上面的模型主流其实是以transformer为主啊，就是简单来讲就是它是以大模型为主的。呃，小模型可能不是特别全，比如说像以前非常有名的。yolo这些模型的话呢，在hang face上面就可能没有那么那么全了哈，那么git HUB上面就标全啊好。然后第一步我们先说一下这个平台上手，我们先得注册注册，并且安装它的环境啊，注册并且安装它的环境。怎么来注册一个账户呢？我说一下这个注册账户的目的是什么哈？刚刚我这给大家看到了，

其实有些模型它提供了呃在线的API使用方法对吧？但是你要使用人家的API，你必须要去干嘛？你必须先得注册。啊，必须性的注册好，我们第一步你访问hank face官网，点击这个右上角，这里面有一个注册。啊，有个注册。没有账号的话，你自己注自己注册一个账号就行了。啊，这儿会要需要做一些这个简简单的验证。

应该选完了。啊，没有的话，你就注册一个账号就行了，好吧，它的注册是支持用这个QQ邮QQ邮邮箱去注册的啊QQ邮箱去注册的。好，我这边有了哈，我就直接登录一下。我登录一下我的这个账号啊。注册好之后就登录啊，注册好之后就登录OK？好，然后注册成功之后的话呢，这里面有一步非常重要的操作，

就是我们要获取。我们自己的这个API token虽然说这个API token没有什么太大的价值。但是第一节课我们要教大家怎么来搞一下啊？好注意看登录进去之后的话呢，这就是在你的个人主页里面，然后右上角这个地方头像点击一下。点击一下进来之后的话呢，它里面有个access tokens，看到没有？有个access tokens啊，access tokens。好进来之后的话呢？在这儿啊，在这儿你们这儿是空的，我把这个删了，

因为我之前带着其他同学注册过，我把这个就删掉啊，删掉好。进来之后的话呢，大家看到的页面跟我是一样的，你这边是空的。你这边是空的，然后呢？我们点击右上角，这里面它有个create new token，就是创建一个新的token啊，创建一个新的token。点击这个create new talking。啊，create new token进来之后的话呢，

在这个token name随便写一个啊，随便写一个，比如说我们就是学个my test。talking啊名字自己随便起啊，随便起完了之后你需要对你的这个应用的这个talking进行授权，我建议是你把所有的框全部给它勾起啊。你看都不用去看，全部给它勾起啊，防止就是有些这个API，到时候你调用有些模型，你通过API调的话呢，没法调对吧？没法调啊，点点不了的话就不点，后面就不不用点了。

把前面这些框全部给它勾勾起，拉到最上面有个create create talking啊，有个create talking点一下，这个create talking。弹出这个页面一定要特别注意一下啊。它这上面有一个提示，非常关键。就是人家一般来讲，我们现在所有的这个AI大模型，你如果去注册这个在线的hi to Ken的话呢，它都会给你弹这么一个窗口，就是下面这一块儿就是你的这个什么呢？你的自己的API token啊，这个token你要保留好，因为这个token你以后看不到了，

这个页面一关是没法打开了。明白了吧，是没法打开的，那怎么办呢？如果你把这个东西丢了，你就只能重新创建一个新的啊，所以把它保留好啊，我们这儿点一下这个拷贝。拷贝你们到时候嗯，把它存好，比如说我们在这儿吧，我就我这儿就随便新建一个文本文档啊。文本文档我给它放到这个文档里面。一定要保留在本地啊，这个东西一定要本地存好啊，

存好到时候你们自己注册一个，到时候我们要用啊。好，保留好之后的话呢，点一下到就可以了。啊，这个这个token我们就创建好了啊，创建好之后我们待会会教你们使用这个token来在线的去访问它的一些这个模型。OK，然后登录之后呢？我们也可以啊，就是我刚刚给大家说了一下，像这个stable de fiction。像这个模型对吧？这个模型它有一个在线的，

这个使用的一个接口，但是你得登录，你登录之后你就可以在线的去应用了。啊，在线的去应用了。呃，这是一个纹身图啊，给大家简单演示一下这个平台的用法。这儿我们搞一段英文啊，这个模型，因为它只支持英文的书，不支持中文啊，搞一段英文。啊，比如我们随便来一个场景吧，

就是一只白色的孔雀。红雀对吧？落在树枝上。啊，落在树枝上OK？好。好，我们复制一下啊，看一下它这个在线的一个API的一个效果。它有些模型提供了接口，你就可以在线的进行测试。嗯，好了，这个模型这玩意出问题了。啊，

应该是它的这个服务器，这会儿有问题哈，启动不了。呃，如果说你们也遇到了这样的情况，在线如果不能用的话呢？那你得换个时间段啊，换个时间段就是我前面提到过哈登费这个，因为它不收费啊，所以说。呃，经常会出一些问题啊，如果你要用在线的话呢，那你就只能换个时间段，要么你就换个模型。

啊，要么我们就换个模型试一下。它有些模型可能会出问题。对吧，换个模型试一下，这是它生成的一个效果图。啊，这是它生成一个效果图，我们你看啊，这搞好了，我们刚刚是刚刚描述了一段话，是一只白色的孔雀落在树枝上，对吧？啊，这是它实时生成的一个效果，

七点四秒。啊，就这十秒，当然这是个多模态模型啊，我们到后面用的其实不是它，只是给你们演示一下人家这个平台，上面是有提供。这个在线的服务的啊，在线的服务的OK？好，那么注册核心是刚刚的API啊，注册好API之后，接下来下一步我们就得在自己的电脑中上面去安装。hang face库来进行访问了。呃，

这儿我说一下啊，因为大家前面应该有是有一些前置课程的是吧？前置课程上面给你们有讲过这个环境的搭建。我们这儿装的这些环境，前提是你得有基础环境啊，前提是得有基础环境呃，我说一下啊，环境搭建。呃，基础环境搭建啊。基础环境搭建。呃，第一啊，大家得装那个p的集成开发包。没有的话，

你们得装一个啊，你们得装一个。呃，第一是passion的passion。我们有一个p的集成开发包。这个环境叫adconda。adconda.我这给你们简单说一下，装些什么东西啊，第一步你先得装一个pation的集成开发环境呃conda。好，如果不会装的同学的话，我简单说一下，你们这个装很简单啊，关键是你要得知道你下什么东西，

对吧？好从编译里面去搜索account啊。呃，笔记，我到时候会发给你们。呃b因里面说第一个就是的download account。啊，download count。嗯，它这里面有一个free download，看到没有？点击这个free download。啊，点击这个free download。它就会给你提供一个下载的一个链接。

啊，这儿有一个让你注册的，你把它跳过就行了，看到没有？刚刚那个邮箱注册认证的给它跳过就行了哈，然后你现在就可以进行这个下载获取了。我们一般是这样的啊，我这说一下，一般是这样的。在前面的这个前面几节课的时候啊，大家可以在自己的这个电脑平台上面，你去装一个这个adconda的集成环境。啊，一般你们可能用的是Windows系统对吧？那你就按照这个WINDOWS去装一个，

把它下下来，64位的，目前是p三点一二版本。装一个就行了，那么我们后面的课程中啊，就是到时候用的模型比较大，我估计你们自己的本地电脑可能很难跑得起来。啊，除非我这说一下啊，我们对于这个显存，大家如果说有些同学有这个比较好的gpu，比如说你有四零九零。那就可以，我们最低的要求是你的gpu在16个GBA的显存以上。最低要有16个GB的显存。

那就够了，如果大家本地有这么一台电脑的话呢，比如说你们现在用的电脑，你说我电脑上面gpu就是16 GB的。英伟达的啊，必须是n卡啊，必须是n卡AMD的不行啊，因为英伟达的16 GBA的这个嗯呃，显存的显卡。那么你就直接在你的电脑上面去装这个东西就可以了。好，那么我们后面的这个课程中哈，我会教大家怎么去使用这个服务器啊？服务器我们主要用gpu的服务器啊。比如说我们需要去跑模型，

跑项目的时候，我们可以临时租一些这个服务器去使用，那么服务器上面环境是基本基础，环境是装好的，你不需要自己去安装。啊，你不需要自己去安装啊，这个环境只是在你们本地电脑上面，你前面你想学学前置课的p啊，全置课的p，或者说我们这两天讲的这个hang face和modo scope上面一些基本使用。那是可以的，没问题的好吧啊，那是可以的，好技术环境就是AD co nda AD co nda，

你这下下来就可以了点这个下下来就可以了，然后它的安装有一个细节。我这简单说一下，安装啊，我们这个上面就不花太多时间，这个基础环境不刷不说太太多时间哈，因为基础环境我前面有讲过怎么安装的，如果你们自己不会的话呢，完了之之后可以。找一下这个助教老师啊嗯，去要一下，就是我们前面有讲过这个简单，有提过这个环境搭建的这个课程啊，应该是有录播课的。好，

这个adconda在安装的时候要注意一个细节。就是其他的，你们不用去管哈，下下来之后next安装I agree看到没有？这儿我告诉你们哈，网上的这个教程最大的坑在这儿哈。不要去选这个东西，不要去选all users，一定要选just me。一定要选just me，那为什么不要选all users？因为你选了all users之后，你就没有办法去授权这个软件自动进行注册。他有一个注册路径。听清楚哈，

有一个自动注册路径的，自动注册路径，它必须得选了just me之后下一个选项点next，下一个选项上面。有四个勾，有四个框框，两个框框一般显示是红色的，你看到没有？它这选了all user就没有那个东西了。没有那个东西会有个问题，你装完之后得干什么？你得自己配环境。我看他这个博客上面，你看啊，他这会你你如果说按照这种装法，

装完之后你得自己配环境就很麻烦，能懂我意思吗？你得自己手动配环境。其实人家是可以自动注册环境的，自动注册环境的前提是你一定要在这选just me，然后第二点击这个下一步的时候，你都是会看到有四个勾选框。有两个是红色的，你给它勾选起就行了，或者你翻译一下，它就是把adconda的这个路径自动添加到这个注册表里面，明白了吧？你就不需要手动添加环境了啊？然后点下一步就完事了啊，很简单，

但是不要去照着这个方式去装，你照着这个方式也装也行，你得记得后面要自己手动配环境啊。好，这是第一个东西，装好之后怎么去验证呢？打开你的这个控制台。你就输入p。窗口回车。啊敲我回车。如果你看到了这么一个信息，对吧？p by adconda那就可以了，就证明你的adconda已经装好了哈，这是第一个环境基础环境。

好，第二个环境呢就是嗯。我们得有这个gpu啊。第二就是cud a。cud a加这个cud n。呃，加cud n。这个东西是需要。有英伟达。啊英伟达的。独立显卡。独立显卡。我这给的建议是显存。16 GB以上啊。啊建建议显存16 GB以上，

你再去装这个东西，不然的话呢，你装它没有太大的意义啊，装它没有太大的意义。OK，好，那么如果有同学说是老师，我前面想自己玩一玩，对吧？我自己玩一玩，我这没有显卡怎么办？没有显卡你就不装了它。它也可以玩passion啊，也可以玩passion啊。好，

然后第三个环境。第三个环境。第三个环节第三个base环境啊，得装paddle ch。啊得装这个paddles。好，给你们简单说一下，这个paddles。一样的啊，在bin里面去搜这个pad touch。好的，官网进来之后呢？在它的首页。往下拉一拉啊，目前最新的stable版本是二点六点一二点六点零。

我建议是什么装最新的啊？装最新的paddle是建议各位装最新的。好。呃，然后呃，这个东西一样的啊，你的电脑里面装的话呢？如果是本地的电脑，对吧？WINDOWS系统，你选WINDOWS，如果你有服务器，你有自己的服务器，那你就选对应的这个Linux系统就行了啊，我们服务器上面一般是Linux系统。

好WINDOWS进来之后的话呢？package我们默认选择用pip去安装哈，你不要用conda CON da特别的慢用pip去安装。语言我们选的是拍摄的啊，然后注意它下面有四个选项，有四个选项就是拍照纸，它也分两个版本，也分版本和版本。啊，也分gpu版本和CPU版本一样的，如果你有16 GBA的这种显卡，你就装个cud a。你去装个kuda，但是要装的同学，我特别强调一点哈kuda和cud n是有版本的，

听清楚啊，这两个东西是有版本的，所以我建议你们先装paddle池啊，先装paddle池，因为。你的的版本是按照paddle的版本来的，能懂我意思吧？你打个比方，比如说拿当前这个paddles为例啊，你说我有gpu，我要装这个gpu版本的，这个paddles那么它的kuda支持11点八十二点四和十二点六的。我建议你们装哪个版本呢？我建议你们装十一点八的。啊，

就是如果说有16 GB的同学，16 GB显卡同学，你们要自己装的话呢，我建议装十一点八的，为什么建议你装十一点八的？或者你装12点十二点四的也可以啊，但是不要装十二点六的就装这两个啊，就装这两个呃，十一点八我们作为贝斯环境来讲的话呢，它的兼容性会强一些。啊，兼容性会强一些，你像我们后面大模型所需要用到一些推理引擎，它有很多是基于扩大十一点八的，但是那个没关系啊，

你说这个地方你装十二点六行不行也可以，但是装了十二点六就可，有可能就变成摆设了啊，所以我建议选前两个啊。选前两个，而如果没有这个扩大的，没有gpu同学，你想在自己电脑上面前面简单跑跑例子的话呢，你就装CPU版本。啊，就装CPU版本好OK？好，这是它这个选项啊，比如说我这选好了，扩大十二点四对吧？

怎么安装呢？下面就是个链接，看到没有？把这个链接复制一下。复制一下，然后打开你的cmd。粘进来敲个回车。它就开始下载安装了。啊，这就开始下载安装了。然后有一个细节要注意一下，如果你这哭大装的是十二点四版本，那么我们在单独安装这个哭大环境的时候。单独安装这个cud a环境的时候也得装十二点四版本，不能选错啊，

选错就不能玩了好吧啊，全错不能玩了，我这边已经装过了啊，我这边之前已经装过了，装过这个paddle是kuda十二点四了。啊，扩大12就是了，你看我这边已经有了一个，看到没有啊？有了一个了，所以它它就不会提示我们再去安装啊，就不会提示我们再去安装了。如果没有的话，它就会下载呃，下载的时候有一个问题哈，

我说一下。一样的，因为这个玩意儿也在外网，所以它的cmd上面下载速度比较慢，怎么办呢？你看一下它如果下载的时候，它这上面会有一个进度条，有个链接地址，你把那个链接你复制到迅雷里面下载。啊，复制到训练里面下载速度会快的，多下好之后的话呢，你找到那个本地文件使用命令pip install后面跟那个文件的路径。本地安装要快一些啊啊，这是一个小技巧，

简单说一下。OK，那么这个是基础环境啊，这个是基础环境。基础环境就这三个啊，听清楚基础环境就这三个，你得有p的集成开发环境包，有adconda有paddle ch。对吧，你需不需要库达和cud n呢？就看你的电脑上面有没有显有没有这个独立显卡了，有韵达独立显卡，你就装一个好，那么有了基础环境之后，我们再来装。

哈根费斯的库明白了吗？这些玩意它是基于呃，它是基于我们的这个基础环境的哈，所以我刚刚简单说了基础环境啊。我们这装了库的话呢，是这样的啊，我我这写了两个环境啊，大家直接装下面这个啊，因为我们后面的这个案例应用中需要用到transformer data set和tos都需要用到哈。啊，我们装下面这这个命令啊，这个装这个命令复制一下我这个电脑上面之前应该是没有装的，我给你们演示一下啊。好把这个命令复制好，加进来，

我这边已经有了技术环境了，这个东西我建议是这样的。就是大家前置课程前面Kevin老师有给你们简单给过一些前置课程是吧？应该有讲过讲过这个p环境的一些构建啊，你们前面应该讲过这个，我们开发的时候构建虚拟环境对吧？尽量用这个空count构建虚拟环境。那个是没问题的，但是注意一下啊，我们今天装的这几个东西，其实都属于它的，就是我们现在大幕型开发的这个什么贝斯环境。听清楚啊，这个属于我们大模型开发的base环境，能理解吧啊，

它是我们的base环境，是我们的基础环境，基础环境的话呢，所以说你像这个transformers这个东西，我建议你可以直接装到base环境里面去。啊，就可以直接装到base环境里面去了，我们到后面做一些这个小的不同类别的，这个demo和任务的时候，到时候再去做区分啊，到时候再去区分也行。啊，我这边又直接装到base环境里面去了啊。好，这边已经我这边之前应该是有装过啊，

应该是有装过的，我看嗯，它这里面有提示这个transformer。啊dataset看到没有？这个dataset的版本是三点三点二的啊，这已经装好了transformer，应该之前是有的，我看一下啊。啊token izers也有。to我是零点二一点零呃hang face HUB呢，是这个呃是transformer里面的transformer看一下啊，我看看我这边装的transformer是哪个版本？transformer.嗯，看一下吧，

我们可以输pip list来看一下你这个装的所有的这个拍摄环境啊。我找一下啊transformer在这儿啊，我这边装的transformer是四点四九点零啊，四点四九点零，因为我是前几天才装过的新环境哈。应该也是目前最新的，反正你们得保证一点，你装的这个东西，我后面是没有跟版本号的，我们装下来就是最新的啊。好环境搭建好之后。OK，这是我们的环境，环境搭建好之后的话呢，我们下一步。

就可以带着各位来实操了啊，就可以带着各位来实操了。好，那么我们今天晚上的话呢，先带着各位来玩一下，参数量不是那么大的模型啊，主要是transformer里面的两个板块GB two和这个bert。这也是我们前期需要用到的两个模型啊，前期实验中需要用到两个模型。好，我们先来搜一下这个吧。啊，看一眼吧啊GB two。怎么搜？在哪搜啊？

我们所有的模型都是在hang face的model里面去搜。啊model里面去搜，我们搜一下这个g bd two。啊GB two那么这个GB two的模型很多啊。看到没有GB two的模型很多啊，这都是基于GB two做的一些二开的模型啊，都是基于GB two做的一些哦，二开的模型。啊，比如说拿这个open AI的，这个open AI社区版本的一个GB two为例，对吧？啊，这这是一个什么模型哈？我带着你们来玩一下。

它就是我们的文本。文本生成的模型。啊文本生成模型open a。呃，之前发布的char TG BT最初的版本其实是叫做GB三点五。啊，距离三点五那么三点五是基于三开发的，三是基于二改良的，能理解吧啊，三是基于二改良的啊，我们今天晚上先来玩这个比较小一点的模型啊，先来玩这个比较小一点模型。好，那么它这也提供了在线的这个API接口访问啊，这样我就不带你们不带走，

各位同这玩了，我们直接通过代码来带，带着大家一起来实操一下啊，带着大家一起来实操一下。OK，好。好，那么下一步的话呢啊，当然这里面你们还得装个东西啊，我说一下基础环境，基础环境我们给大家装一个开发工具。开发工具啊。这个project的管理工具，我们我们安装的是拍。啊，

我们装拍摄嘛就干嘛用的管理项目用的写代码用的啊，我们AI上面需要去做一些比较简单的这个代码前在在前面这个阶段。需要做一些简单的代码，后面的话呢，就基本用不到了啊，前期做开发需要用到这些东西啊p，我也说了一个p怎么安装？呃，来看一下这个拍串啊。呃，注意啊py chrome有两个版本。一定要去官网哈，我说的这些东西一定要去官网去安装进来之后的话呢，这里面有两个版本，我们装社区版。

这是它的专业版本，看到没有专业版本不要去装专业版啊，专业版我们用不到啊，它的功能我们用不到，并且专业版是需要收费的。你往下滑一下。它有个社，这个又改了嘛，它社区版跑哪去了？这是专业版，社区版的。马上我看一眼啊。这个页面老是在变。futures.哎，

他把摄血板藏哪去了？之前就下面就放了社区版。那这个这个不是啊。我点进去是不是在下载里面呢？哦哦，对对对。对这个页面现在又变了，你要点一下download download它要跳转。跳转到下载页面看到没有？这个是专业版往下滑，下面这个是社区版本，你们下载社区版本哈，到时候我们我们不不管说是。这个你们后面用不用服务器呀？这个东西得有哎，

因为我们后面需要去做一些代码的编辑，用的是p下这个版本啊，下这个版本。这玩意儿你下下来没有什么特殊的哈，就下一步下一步下一步就完事儿了啊，下一步下一步下一步安装就完事儿了啊，这个没有什么技巧。然后刚刚我看到有同学在问那个库大有没有安装文档，有这玩意儿，你们百度一下吧，那文档多的很。对吧，扩大的安装。啊孤岛的安装，你是WINDOWS你就搜WINDOWS的，

你是那个Linux系统，你就搜Linux系统的，如果你是mac的话呢，我就不建议你装了啊，因为mac装这个东西没有太大的意义。能懂我意思吧，麦克一般不带有英伟达的独独显，除非你是几万块钱买的那个麦克，那么它就会有英伟达的独显啊，因为麦克的性价比其实不是特别高啊。呃，这上面有详细的文档，你这这这个东西不难啊，就是你看一下它嗯，你你其实你搜一下扩大的那个对应版本下下来就行了，

它没什么坑。就下一步下一步啊，没有什么特别需要注意的好吧呃，如果说自己觉得看这个文档有问题，你们完了找一下助教老师，我们前面是有这个安装的视频的哈，我记得之前是有过的啊。好，这是基础环境，然后我这儿就打开我们的这个拍摄目啊，带着大家试操第一个拍摄目下好之后就转这个这个窗口界面哈，我们双击打开。啊双击打开，打开之后的话呢，大家可以看到你，

如果是第一次打开的话呢，界面基本跟我这一样啊，有个location location是你创建项目的位置。哎，location是你创建项目的位置，这个你放到你的这个呃对应的磁盘就行了啊，我这边把这个项目放到D盘。啊D盘。好D盘pattern project，然后取个这个名称啊，名称我们今天就是demo 1啊。demo 1啊，demo 1。好，那么接下来的话，

它需要你去选一个环境。看到没有，需要你去选一个环境，这边是创建一个新的虚拟环境。啊，创建系列环境，我我们就不要去搞虚拟环境了啊，你就闯，你就直接用你的这个物理环境就行了好吧啊，物理环境就行了，因为我刚刚说过了，我们前期用不到这个虚拟环境。先用它的这个base环境就可以了啊，我这边这个base环境你要选择谁呢？一定要选择这个base环境，

你们一开始可能没有。没有没有的话，你选择这个添加。做一个添加本地的环境。绑定环境里面，我们这选择system看到没有？system你这边之前可能是空的啊，之前可能是空的，如果空的话点一下，后面这个省略号。点下后面一个省略号，它会弹出来这么一个窗口，然后呢？找哪个东西呢？找你下载好的adconda我前面说过了啊，

你又你得下载一个这个adconda的集群环境。比如说我这个adcond，我是放在D盘的my soft AD cond上面这个文件夹展开以后，下面有个p点EXE。点一下这个p点EXE OK，这就可以了，然后把它点击添加就行了，明白了吧？这就可以找得到了哈，所以你这个环境一定要用哪个呢？一定要用你的aconda下面的pasi on啊，一定要用你的aconda下面的这个pasi on啊。然后create创建一下。啊，创建一下好这儿，

等它这个加载技术环境就行了。啊，这个project我们就构建好了呃，多说一句啊，需要在自己电脑上面去搭建环境的同学。你说我电脑上面有这个16 GB的，这个显卡对吧？我就要在我的电脑上面，后面做开发，那么各位记住了，你在装环境之前，你先把你的系统。重新装一下。一定要把系统重新装一下，因为你们这个window系统用久了，

会有各种问题，很有可能会导致你的环境安装失败。然后win 10 win 10的用户啊。我说一件事儿，装环境的同学win 10的用户，你的系统必须得装专业版本，不能装家庭版本，家庭版本上面环境搭不起啊。WINDOWS是分这个版本的啊，如果是用WINDOWS的同学，你要在你的电脑上面去装环境，你的Windows系统必须得装专业版本。而且记住一定要把电脑重新装一下啊，装完之后再去搭环境啊。家庭版本是不能用的，

家庭版本这些东西不能用啊。OK，这是环境上面一些这个建议啊，给大家一些建议。好，那么你是第一次构建好这个环境的话呢，这里等一等，因为它得从我们的那个我的content集成环境里面去加载，那么第一次加载需要花点时间。啊，花点时间，你让他加载就行了啊，不用去管它好，那么接下来我们带着各位来实操啊，第一部分我们先说一下这个API。

好，我们选择这个project右键new一下，一个directory，我们这分开一个新的包，叫做我们先说API吧，我们API test。呃API test。呃API test，OK？好，我们先看第一个案例啊，先教大家怎么使用这个hang face？在线的去调用。啊嗯，它的这个hang face上面的一些AP呃模型啊。

API test零一吧。啊零一好，我们先来看第一个案例。啊，第一个案例。呃。我这儿先教大家来用第一个案例啊，第一个案例好，我们通过hand face的models里面。我们先搜第一个，这个g bd two模型搜这个，我们选择一个g bd two的一个中文模型，看到没有？啊，中文模型啊，

叫做你输GB two Chinese，其实就搜的出来啊，好进来之后的话呢，就是这个模型的名字。然后这个模型我们先说在线的使用啊，先说在线的使用怎么来在线使用这个模型呢？来看一下，我们导入一个包。啊import这个包叫request。啊，request。然后在线调用的话呢，我们得给它设置一个API URL URL。啊API URL好，那么这个API地址是这样的，

它前面就是哈根菲斯的网站地址。看到没有hank face这个网站里有个HD BS呃杠hank face点co啊hank face点co。好，我们把它复制一下，但这个地址我们通过API访问的话呢，得改一改。啊，得改一改好怎么来改呢？这个haagen face点co的前面我们加一个叫做API杠inferences啊API的这个访问接口。加这一段东西啊。啊加这一段东西，后面点跟hang face点sell啊hang face点。好，然后后面就跟的是一个目录，叫models。

呃，models models目录在后面就跟你的模型名字就行了，你比如说我们现在用这个模型对吧？那么这个模型的名字你不要这样去复制啊，不要这样去复制。啊，看清楚它后面有一个什么有个copy啊，有个copy按钮，你点一下这个copy按钮啊，点一下这个copy按钮给它直接粘到这个。models的后面就可以了。而且特别要记住一个问题啊，我们在这拿的是模型的完整路径。听清楚啊，拿的是模型的完整路径，

回过头给你们看一下，目前hand face model上面你们你我们在这儿去找模型的时候，大家会习以为常的认为我们所谓的模型名字指的是后面这个，其实是错了。我们的模型名字是人家这显示出来这个完整的路径。看到没有啊，是这个完整的路径啊，完整的路径不是只是后面那个斜杠，后面那一部分的，所以说我们在这拷贝的时候，你不要自己不要自己在这自己去拷贝啊。你点去任何一个模型，后面一个拷贝按钮，点一下点一下，给它粘到后面就行了，

明白了吧啊？这是我们要访问这个模型的，这个API的一个路径地址啊。好，那么API的访问hang f提供了两种方法，第一种就是你其实可以不注册，但是不注册目前基本是不能使用的。我们先说第一种语法就是不使用。呃，不使用这个talking？呃进行匿名访问。进行。匿名访问。但是，这种访问经常会失败啊，

我先教你们怎么来用？呃，response。嗯，response。就等于我们刚刚导那个包request点post。啊，我们通过一个post请求传入这个API URL。然后的话呢呃，我们访问的内容以这个json的字符串分装好，给它返回进去啊，json字符串分装好。好，那么给一个参数叫input。这个input相当于说我对模型的提问啊，

相当于我对模型的提问，后面跟的是input的内容，比如说我们就问他一句话，就是你好。h face呃，我们来看一下它能不能给我们进行这个？呃，响应啊，响应那么响应的结果的话呢，我们把它输出print一下，这个response。啊response嗯嗯，response。啊print一下这个response，然后它的内容的话呢，

我们也让它以json的形式返回就可以了，就几行代码啊，几行代码。但是这种访问不一定会成功啊，我们试一下。啊，这是匿名访问，匿名访问就是不输入token啊，不输入token。啊，你看它现在不行，现在不行了，看到没有？现在不行了，现在必须要进行登录了，

那以前的话是匿名可以了，那现在版本它不允许匿名访问了，你必须要登录啊，必须要登录。所以这种方法，那你们现在就就弃用了吧啊，就弃用了吧，因为之前上个班的时候都可以啊，现在呢，平台改改改了一个版本。OK，那么我们就直接进入第二种啊，就是刚刚注册了一个talking嘛，对吧？我们看一下这个使用自己的talking啊。

来进行访问。啊，这个是零二啊，我们再新建一个这个零二。API test.零二。好，这是使用这个API访问啊，我们还是用这个模型把这一块复制一下。修改一下，这儿加个东西，这儿加一个API token，API token。啊API token，API token就是我刚刚最开始教大家注册的，

保留下来的那个hang face的API token复制一下。给它粘进来。嗯，转起来。好，然后我们得给它添加一个头部。添加headers。啊添一个headers。然后头部headers header里面这样去设置啊，就是做一个这个什么呢？登录认证对吧？然后后面添加的是我们的注册好的这个API token。好，然后我们在响应的时候，这是使用token啊，

使用token进行访问啊。使用talking进行访问，我们在进行pose请求的时候，除了添加这个API URL以外的话呢，再给它添加一个headers啊。啊，headers就等于我们的这个headers把这个header把这个头请求头给它加进去啊，请求头给它加进去，其实就是把做一个用户的一个认证。然后再去请求啊，然后再去请求，那么现在基本上就可以得到这个响应了，但是这种方式我还是那句话啊，虽然说。诶，

我看一下。怎么提示报错了呢？杰森蒂克尔。message post.那这玩意儿，它不应该改版吧？我看。message.decode error.我是不是字符串写错了？json json.哪里啊？你们说什么地方多了一个多了个s啊？json的格式不对嘛。对的呀。

也就是这边的返回没问题哈。had r的json不对。然后我我看一下。哎，不要乱讲中文逗号，编辑上面就出来了啊。第五行。这个没错的啊，这个没错的啊，这个肯定要加哈，你不加的话token加不进去啊。这是格式化语句哈，不是不在那问题，不在那哈。诶，

它怎么现在这个不能请求了吗？是不是hank face这个版本更新之后API变了呢？等一下，我把我之前写的那个。拿过来哈。稍等一下，把之前写的这个拿过来看一下。talking换一下。没有，我感觉是不是hang face的新版本更新之后，它是不是用法变了？看一下诶，那我刚刚什么地方写错了？呃，我换了一下就可以了。

我拖过去看一下啊，我排排查一下错误，我刚刚什么地方敲错了？前面这不可能有问题，前面这都是对的啊。if you are talking request poster.b对的呀。诶，奇了怪了，为什么我之前写的可以用刚刚写的这个就不能用了？header.headers=headers，没错呀。啊，那不算了，

不纠结了啊，不纠结了。那就这个用法，这个用法我把它换过来。应该是哪个字符敲错了啊？啊，哪个字符敲错了？没关系，我们直接看，结果这就不不不耽搁你们时间了。好，就是这种用法啊，使用token在线访问，这是你模型的地址，我们刚刚这儿就给它加了一个hi to Ken。

啊，加个token，加一个请求头，然后你把你的请求头传进来就行了，明白了吧？请求头传进来就行了哈，这就可以生成响应了，看到没有？我们刚刚这已经生成结果了啊，已经生成结果了。啊因因为它是个续写模型，我说一下啊，这个GB two是个续写模型，所以你给它给一个开头，它就会跟着这个开头继续往后写。

明白了吧啊，它就跟着开头继续往下写啊，这是API的请求呃，当然这个API请求这种这种方法我不推荐，为什么不推荐我给你们多跑几次，你们就明白了。因为这个玩意儿啊嗯，它不是很稳定。就是如果这会儿网络环境好的话，或者说hang face这个服务器目前用的人比较少的情况下。它这个生成会比较顺畅，就是你这个调用返回结果会比较顺畅，能理解我意思吧，如果说网络环境不好，或者说这块儿它的服务器别人用的比较多的情况下。

这经常会响应失败啊，经常会响应失败报错。经常会出这个情况啊，所以说是不建议各位不建议各位在这个上面去做呃，在线的这种调用的哈，虽然说我们今天晚上我刚刚这跑了好几次，你看这个响应还是比较快的。诶，你看啊，这个选项还是比较快的，但是你们到时候可以多换几个时间段去试一试好吧啊，多换几个时间段去试一试啊。啊，这是这个API的一个第一种用法呃，多提一句，

如果说各位对这个模型哈，你有一些其他的一些想测试的。我们这儿课程上面我讲的是。讲的是使用这个g bd two啊，你们也可以去试试其他的模型啊，试试其他模型，因为任何一个模型，我刚刚说过了，你点开之后，它下面有用法。看到没有，它下面有用法，但是人家上面这儿给的就是官方给给你的这个用法，它都是本地的用法啊，都是本地的调用方法，

就是你如果直接去调用它这种代码的话呢？它会把这个模型加到你的本地来进行使用，明白了吗？会加到你的本地来进行使用啊？好好，这是API啊API API的访问API这个东西呃，大家体验一下就行了啊，因为我们后面都不建议用这种方法啊，接下来我说一下怎么把这个模型？搞到本地来玩啊，搞到本地来玩。OK.好，我们新建一个这个文件夹。呃，

本地的模型的库的话呢？我们是基于transformer构建的。transformers啊，我这起个包就是transformers test。啊transformer test。好，我们先给大家教啊，接下来这个就是比较重要了哈，这个就得掌握了，教一下大家怎么使用这个汉字？hang face的SDK把模型下到本地来进行调用啊。好将模型。下载到本地调用。啊，将模型下载到本地调用啊好，

我们怎么来下模型呢？嗯，导入transformers啊，transformers。它上面有一个嗯，有两个有有有两个模块，一个叫做auto。model啊，auto model。因为我们现在这个生成模型，生成模型的话呢，它有一个请求头啊，它有一个生成头啊，我们就调用这个模型automotive of for clm啊，这个是生成，

这个是模型。导模型用的，然后这个自然域大模型哈，它在进行文本编译的时候，它需要有一个分词工具，有个字典工具啊，我们还得导一个包，叫做auto toke na der啊。导，这两个包注意这个是模型，这个放的是分词器啊，分词器分词器的话呢，我们这节课还给大家介绍不到啊，下节课会给你们讲到这个分词器。啊，

就是这个这个东西哈，这个东西是目前自然语义的一个，关键就是我们怎么把文本？怎么把文本变成是这个模型，可识别的东西靠的就是它啊，靠的就是它啊，所以说模型跟它的分词工具是一一对应的。那这个也这一点你记住啊，模型跟分子工具是一一对应的。它们两个一定是一一对应的啊，所以我们得导这两个包进来，然后的话呢，下一步就是将模型将模型。和分磁器和分磁器。和分词器我们下载分词器下载到本地。

啊，下载到本地，并且指定保存路径。啊，保存路径好model name。啊model name model name的话呢，就是我们刚刚搜索的这个模型的名字。拷贝一下。拷贝一下。好粘进来。model name第二个就是我们的呃保存的路径。catch directory啊。这个路径你自己来设啊，这个路径你自己来设置，就是说你希望把这个模型保存到哪里，

对吧？我这边的话呢，为了大家方便，我到时候把整个项目传给你们，里面是自带模型的，我就把模型放到这个什么呢？项目里面啊，就放到这个项目里面，放到这个项目下面，我创建一个文件夹叫model。创建一个文件叫model，model里面就放这个模型啊，model里面就放这个模型好，这是给个相对路径。好OK，

然后的话呢，下一步我们来下载。下载模型。啊，下载模型模型下载就调用这个auto model for就是我们导进来这个包啊，模型包啊。它点一下，有个from print。啊，from printed传入model name。呃，model name，然后给一个参数，叫做catch directory。呃，

catch directory就等于我们的这个什么catch directory给它保存到你指定的这个路径里面去啊。如果是Linux系统的同学，你这就要给绝对路径了啊，因为我这边是WINDOWS啊，这是我们的模型好，然后下一步我们就下载这个分词工具。啊，下载这个分词工具好auto tokenizer一样的啊，点from tree trade。它里面参数跟这个模型参数一样，传入你的这个什么呢model name？再传入这个catch directory。这个分词器一定要跟模型放在同一个位置啊，一定要跟模型放在同一个位置，这一点要特别注意，

因为这两个东西是一体的啊，这两个东西是一体的，所以我们缓冲路径一定是在一起的，它的名字也一样。其实我们后面用的所有的大模型，你在下模型的同时，它会把这个分析自动给你下好啊。好执一执行这两段代码就开始下载了。明白了吧啊，我们这儿给一个给一个什么给一个提示啊，给个提示。模型分词器。已下载。已下载到。这个catch directory啊，

一个提示好，然后你右键run。啊，就可以。联网去获取下载了。呃，这注意啊，这网络一定得通，网络一定得通，你一定得能够上外网，如果你需要自己下的话呢，你必须得能够上外网啊。因为我们目前hang face平台上面的所有的模型和数据集都是放在谷歌云盘里面的。换句话来讲，你的网络如果可以访问谷歌网络啊，

谷歌云盘，那它就可以下载，不然的话呢？可能会下载不了，或者说这个速度非常的慢啊，会有这么一个问题呃，因此为了避免就是大家由于网络原因所导致，你们到时候自己下不下来，这个模型没法用哈。我会把这个模型文件一起打包发给你们啊，一起打包发给你们，我们这儿给大家要看一眼，是我看这个。这个网络是有哈，这个网络是有，

它应该是有在下载了。但是这个地方会很慢，哪怕你挂了这个梯子也会很慢啊。好，这开始了，这开始了。才开始啊。然后说一下呃，说一下。因为大家很多是做开发的，做开发的同学以前做JAVA或者做其他PHP开发的同学。因为我们以前那个编辑器上面哈，看到红色的。基基本都是报错，但是p这个上面它其实红色不是error啊，

它是警告。啊，它是警告，这个警告你可以不用去管啊，警告你不用去管这个东西，因为我们做的不是软件开发，你不用去管它有没有bug的问题？因为本身是它框架里面的东西，明白了吧啊，本身它框架里面的东西有警告很正常啊，不用去管警告好，这边已经下好了啊，这边已经下好了。就是呃hang feed这个平台上面。有一个比较麻烦的地方在哪呢？

它的模型在下载的时候啊，大多数模型在这个p的这个控制台里面，它是没有进度条的。明白了吧，所以说你得多花点耐心啊，如果要自己下。好下好，我们这儿刷新看一下啊。啊，看到没有？这里面就有一个model文件夹model文件夹，然后点开以后注意看，这是我们刚刚下的这个模型，看到没有？啊，

我们刚刚下的这个模型，然后我给大家说个重点啊。这个文件夹的结构目录，你们得记住，因为以后我们所有的自然语言大模型的这个结构基本和这个东西是差不多的。你们可以看到这里面有两个文件夹，这个点locks里面没有我们要的东西，它是空的啊，你不用去管模型在哪呢，模型在这个model里面。啊，在这个models后面跟这个杠user里面把它展开。展开之后呢，前面这三个文件夹都没有我们要的东西啊，有一个snapshot模型在这个snapshot里面，

点开以后。点开以后。哎，这怎么下了两个呢？那它这个模型可能还分开的啊啊，它这个模型可能还分开的现在。g bd two这个模型现在还分开了，大多数模型呢，是放在一起的，没关系啊，你看剪开以后它这里面有有有些模型是一个文件夹，有些模型是两个文件夹。啊，两个文件夹好，然后注意看这个model点safety tensors就是我们要下的模型啊，

这个要记住啊model点safety safety tensors就是我们要要的模型。它有些模型可能不是safety tensor的格式，有些模型可能是点pd的格式，但是那个无所谓啊，它都是我们要的模型，然后这个config是模型的配置文件。啊，这个是config configure是模型的配置文件，你点进去可以看到它里面有模型的一些基本介绍啊，有模型的一些基本介绍，比如说这个。呃，模型的头是GB two的一个生成模型，它是GB two的一个生成模型，然后下面这是模型的一些配置参数啊。

啊，模型的配置参数。OK，这里面详细参数，我们现在就我们先不说啊，后面我们会给大家去介绍我们所需要用到的一些这个结果啊。呃，目前你们先记住这个词啊，把这两个把这两个东西注意一下。这个vocab ti ze呢？我前面提到过了，这个自然语语模型，它得做一件事，就是它识别的这个文字是有限的，听清楚啊。

我们现在的这个字文本语言模型不是万能的啊，它能够识别的这个字符字符或者文字是有限的。你比如我们现在用的这个g bd two的这个中文模型，它能够识别的这个文字有多少个呢？就是文字字符啊，有二幺幺二八。这是它字典的数量啊，这是它字典的数量，然后这个模型的字典呢，是基于bort的。这个模bort的字眼构建的啊，是基于bort字典构建的OK啊，这是模型的配置文件，然后大家这可以看到它，还有还有个什么有个paddles model点bin对吧，

那么它这个模型提供了两套权重。有hang face的格式，有这个paddle的格式啊，因为这个hang face本身是基于paddle啊，然后下面这个special talks map里面里面主要是定义了一些特殊字符。啊，定义了一些特殊字符，那么大多数的这个GB two或者的这个模型里面哈常见的特殊字符，其实就这五个。啊，这五个我简单说一下，这个特殊字符是用来干什么的？特殊字符就是用来做一些特殊的代表的，比如拿这个unk为例啊，拿这个unk为例。

我们刚刚看到了这个嗯config里面啊，他提到的字典数有二幺幺二八，就是言外之意是它能够识别的字符就二幺幺二八个，对吧？那万一注意听，那万一万一这个模型在进行输入的时候，我这个文本里面它有一个字符很特殊，这个字符不包含在人家这二幺幺二八个里面。那怎么办呢？不就报错了吗？对不对？人家这有有办法，如果这个字符不存在于二幺幺二八个，那就给它编码，为什么unk？

啊unk啊unk啊，这就是special tokens的作用。啊，这个unk就是代表我未识别的字符，就不包含在它的二幺幺二八个里面哈，那么后面这个SAP。add pad就是这个东西，一般是做填充的啊，这个是头尾。就是头尾啊，头尾，然后呃mask是做这个掩盖的啊，做掩盖的就是有特殊含义的这个字符啊。上面这个token I zer config token I zer config，这是跟呃字典相关的字典相关的啊，

比如说我们现在的自然语言文本。啊，自然语言模型，它输入的文本是有长度限制的，各位知道吧？比如你们用那个kimi啊，是不是轻言啊？对吧？这些自然语言对话模型，它输入的时候是有文本长度限制的。那一样的哈GB two模型本身就有长度限制，你看这个模型，这个模型有一个max lens。它支持最大的长度是幺六二四。啊，

这是最大的长度，是幺零二四，如果你超过幺零二四，它也不会报错，它会把这个文本截断啊，这块儿细节我们在应该是下节课会讲到哈，今天先简单看一下。啊，这是模型的长度的一个就是字典相关的一些配置，然后这个模型能够识别的所有字符在这个vocab点text里面。啊，我cup点text里面。往下拉一拉，看到没有？这是它，

这是它的字眼啊，它能够识别的所有字都在这个里面。明白了吗啊，能够识别的所有字都在这个里面哈，一共有二幺幺二八个字符啊，二幺幺二八个字符，所以可以满足我们基本的这个日常使用是没有任何问题的。好，这是整个模型的这个文件结构哈，这个文件结构其实很简单，对它有个大致的了解就行了，好吧？AI这个模型，你把它下到本地了，下到本地之后的话呢，

我们就可以在本地来进行调用了，能理解我意思吧，只要本地有模型。那你哪怕是断网了，都可以用，那哪怕是断网了，都可以用啊。OK，那么接下来我们教教大家怎么来本地调用模型啊？本地调用模型。OK，我们就在这个。里面构建第二个案例test零二。嗯，这是本地调用这个模型啊。

本地本地离线调用。这个jvdt two。啊GB two好，我们需要用到这么几个包啊，第一个你得把模型加进来，那就是刚刚的transformers的两个包，一个是我们的模型。auto啊model还有一个叫做auto。token izer对吧？好，那么接下来我们要用这个模型，用模型的话呢呃hagen face平台，它也提供了一个工具，这个工具叫做pipeline啊。啊，

我们基于这个pipeline啊来调用我们的模型啊。第一步，我们需得设置模型的路径啊，设置具体包含。具体包含呃，这个模型的路径怎么来配也是个学问啊，也是个学问，注意啊，模型的路径在哪里呢？模型的路径在这个里面。你怎么判断模型路径呢？我这告诉你们。你看哪个文件夹里面包含了这个config点json？啊，那么这个文件夹就是模型的根目录啊？

包含config点json。呃，设置具体包含CON config点json。的目录好，我们的model directory。这个路径要给到哪里？要给到给到这个位置，给到这个文件夹拷贝一下路径，并且切记哈，这个路径只支持绝对路径。相对路径不支持啊，它只支持绝对路径，就是你得带盘符。这记住，只支持绝对路径。

且呃，这说一下只支持。绝对路径。就是你得在盘符号啊，你给相对路径不行，那么WINDOWS上面有一个毛病是什么？我们拷贝这个路径，它它这个斜杠是反着的。反着的有些字符会被转译啊，像这个反斜杠t就被转移了，那怎么办呢？有两个方法，第一个是你把这个反斜杠呢换过来。给它换成这个正斜杠，但是这就有点麻烦，

有点慢，对吧？我们一般建议是字符串前面加个转移字符，加一个r就行了。只要转移字符啊，这个防转移字符就行了。OK好，这个目录一定得设置清楚啊，只支持许多图形，那么下面的操作就跟刚刚比较类似了哈，那么下一步我们就来加载。模型和分支线。加载模型和分词器啊，加载模型和分词器。model就等于我们的auto model。

点from print，这里面把model direct给它传进来，模型就来了toke na der。嗯izer啊。talking neither就等于我们的auto talk neither点from print trade一样的啊，给到这个model directory。啊，就可以了啊，就可以了，然后。我们就可以使用。使用啊，使用。加载的模型。和分词器。

呃分词器创建生成文本，因为我们现在j BD two模型啊，它是文本生成的一个模型，生成文本的这个啊。啊，创建生成文本的这个pipeline啊。好诶，这个拍不来工具。啊调用这个pipeline来做这个模型的生成啊，来做文本的生成好，我们构建一个变量generator。呃，generator就等于我们的pipeline。这个pipeline里面的话呢，你得标记一下这个pipeline工具的类型，

我们现在是文本生成叫text generation。呃，generation。OK，然后传入参数model=model。把模型给到它，然后toke na der就等于我们的这个toke na der。啊，最后一个参数device。我说一下这个参数啊，这是设定当前推理的工具类型的。device里面，我们可以填两个参数，一个是CPU。CPU是什么意思？

就是你跑代码的这台电脑上面，如果是没有装，没有这个独立显卡，没有装cud a这个版本的环境的话呢，你这就用CPU去跑，它也可以跑。但是可能就有点慢啊，就有点慢好，如果你有这个英伟达显卡，并且装了这个paddles酷达版本的话呢，这就可以装这个gpu版本啊，那我们先来看一下这个CPU版本。好最后生成响应啊print一下这个generator。啊，这不是print，

接下来我们生成响应啊，生成生成文本。叫你们来生成文本，生成文本。生成文本啊，生成文本好，我们的output output就等于我们的这个generator。好里面怎么来用呢？第一段话是一个提示词，先把你的这个提示词输给它啊，比如说我们这随便输一个就是你好。我是一款。语言模型。啊，我是一款语言模型逗号，

然后让它开始续写啊，让它开始续写。啊，接下来我们得对得对这个生成的结果作为控制，比如说max lens。呃，这怎么没提示了啊？就是最大的生成长度，对吧？我们控制一下，不让它生成太多啊，生成50个就行了。然后还有一个叫做number。算了，没提示，

我拷拷贝一下，它有时候可能没提示啊，没提示你们到时候直接拷贝一下就行了啊。有个number return sequence，就是说我们需要让这个模型它续写的结果是以几句话返回，对吧？我们就让它返回一句话就行了。啊，返回一句话就行了，好这样把这个结果输出一下print一下，这个output。啊print一下这个output啊OK好，我先用CPU给你跑一下啊。啊CPU我们跑一下。CPU跑的话，

我们CPU CPU比较老了啊，但是它还是可以跑啊，CPU跑的话，它主要是。靠，你的内存主要是靠你内存啊。你内存够的话，它就可以跑，但是CPU会慢一些。啊CPU会慢一些。看到没有，它会提示你，你的这个设备用的是什么CPU？看到没有啊，设备用的是CPU啊。

好，你看这个续写就成功了，对吧？你好，我是一款语言模型程序员，我想问大家对于我这样的学生有什么方法？我会学到进入技术哈。首先，我们先不要去管这个结果啊，这个结果是已经生成了，但是这个结果不好，看到没有这个结果不好，就是它生成的内容跟我们的这个什么呢？跟我们的这个提示词好像没多大的关系，对吧啊？

确实是这样的呃，原因在哪呢？原因在于两点，第一点，你们要注意一个点啊，就是我们现在这个模型本身不大啊。这个大模型，并这个严格意义上来讲，它不是大模型，它是gb at的第二代，只有401M啊，只有401M。模型本身的这个权重也不大参，数量也不大，所以效果肯定没有你们现在所看到的自自然语言模型那么好，

这是其一其二。其实这个自然语模型效果好不好？它得通过我们的后处理进行控制，我们现在是没有给它做任何的这个配置和设置的，明白了吧？所以这个效果不是特别理想。如果你希望这个效果变好一些的话呢，我们可以给大家做一些这个参数的控制啊，做一些参数控制，那么这个参数控制的话呢，我给大家这儿。把最终的这个版本写好了，我们简单给你们看一下这个效果啊，这块儿我就注释掉了。这个方法我们就先注释掉啊，

一般我们基本的用法，它的效果不是特别理想，你加一些这个条件控制。啊，加一些这个呃条件控制它的效果就会好一些啊，好刚刚看的是CPU调用，然后我这给你们演示一下gpu gpu的话呢，这里面就选库的。但是你得有那个gpu的环境啊，你有gpu的环境，这用用导的话呢，它就会用显存去跑啊，用显存会去跑会稍微快一点点啊。好，我们来看一下啊，

最终极的这个用法是这样来用的，这个拍拍工具它里面支持一些参数来进行控制。第一个参数是不变的啊，就是我们的提示词，提示词你好，我是一款语言模型，对吧？这是我们的提示词，然后max lens我刚刚说过了，这是我们指定文本生成的最大长度。啊，就是我们给它限制成五限制到50个字就可以了，重点看一下效果，下面这个呢是指定参数返回多少独立生成的文本序列？比如说你给一的话呢，

就返回的是一段文本，对吧？我们这儿具体看一啊看一，然后这里面一个这个truncation truncation是什么意思呢？就是这个参数啊，决定是否截断输入文本，以适应模型的最大输入长度什么意思啊？注意看。其实我们刚刚这直接来跑的话，你看这有个警告叫truncation is not没有进行设置，看到没有什么意思呢？这个模型config我刚给大家看过啊，这个模型的模型里面还有一个max lens。呃，在这个图里面啊，

这里面有一个max lens，看到没有？它最大的输入长度是幺零二四啊幺零二四。就是如果这个模型我们现在给它输入的这个内容啊，输入这个这段文本就这段文本的长度，如果超过了幺二二四，它就报错了。明白没有，你没有设置truncation为true就报错了，你设置为了truncation为true之后它就不会报错了啊，就超过的部分就截断了。看到没有？如果为true模型输入的最大长度超出最大长度，就会被截断，如果为FALSE的话呢，

就会报错。啊，所以说它一般建议你的是这个truncation要设置出这个，当然这个东西不会影响到生成结果哈，影响到生成结果的主要是下面的这几个参数。temperature temperature这个叫我们一般把它叫温度系数。这个参数也比较重要，它起个什么作用哈？这几个参数这几个参数后面这几个参数要注意一下，这三个参数要注意一下，因为我们后面所有的。所有的自然域达模型上面都有这三个参数，到时候你们可以根据生成的效果来对这个三三个参数进行调整啊，你得知道它怎么调啊，我们这说一下。

这个template呃，它是控制是文本生成的随机性的。什么叫文本生成的随机性的呢？我简单说一下AI是怎么生成文本的？哈AI是怎么生成文本的？讲一下这个逻辑原理，你们就明白这个参数的意思了。你像我们这输了一段提示词对吧？那么这段提示词会给到我们的AI模型。注意听啊。它会给到我们的AI模型，这是给大家讲原理部分了。AI模型拿到这个提示词之后，它要做的事是什么？是续写。

是续写。但是AI它怎么会写字的呢？这个模型本质上它不会生成文本，听清楚它不会生成文本，它识别的文本是有限的。这个模型本质上能够识别多少个文本呢？多少个字符呢？刚刚你们看过了，是二幺幺二八。所以这个模型最后一层的输出，最后一层的输出是。二幺幺二八它会输出二幺幺二八个值。这二幺幺二八个值对应的就是它字典里面二幺幺二八个字符，每个值代表的是一个概率。听清楚啊，

每个值代表的是一个概率。然后。比如说我刚刚这给了他一段体育测，说我说你好，我是一款语言模型逗号对吧？那么这个逗号后面模型拿到这句话之后，他要他要。他要去预测这个逗号，后面就这句话的逗号，后面我可以跟哪些词能懂我意思吧？可以跟哪些词？它其实给到我们是二幺幺二八的概率，那么这二幺二二幺幺二八的概率我用哪一个呢？你就是通过这些参数来控制的。理解没有啊，

通过这个参数来控制的好，比如说这个temperature起到一个什么作用，它控制文本的随机性就什么意思？你从二幺幺28个里面随机的去取，能理解我意思吧，随机的去取啊，随机的去取。这个值越低呢，文本是这个生成的，文本越保守就值越低呢，它的随机性就越低。那值越低，随机性就越低，就倾向于选择概率较高的词。简单来讲，

比如说这个值我改成零，它就没有随机性了，没有随机性选哪个呢？选二幺幺二八个概率，里面概率最大的那个结果。所以它就每次的结果基本就是一样的了哈，就这个意思值越高呢，生成的文本越多样，就生成于这个倾向于选择不同的词，它的随机性就高了。啊，随机性就高了那么零点七呢，是比较常见的一个什么设置就保留了随机性，又不至于太混乱啊，不至于太混乱，

这是temperature的控制。所以这个这个值的怎么来设置呢？我们一般默认是给个零点七。但是如果你们觉得这个文本的这个生成的这个随机性太强了，我不想以那么强的随机性，我就把值给低一些。如果我觉得这个文本身的随机性不够，我就把值给高一些啊，就这个意思啊，这是控制随机性的，然后top k。top key.这个是限制模型，在每一步生成时，仅从概率最高的k个词中去选择下一个词。

比如我们刚刚这给个50。你看啊，这个temperature零点七的概率去随意的去取，那么它随意的随意的去取，从二幺幺二八个里面去取吗？不是。是从这个top k里面去取，明白了吧？就是我们拿到二幺幺二八个概率之后top k里面就决定了我。概率从大到小排个序。排过去取前50个。前50个概率最大了，然后以零点七的这个概率去随机的从50个里面去取，能懂我意思吧啊，是这样的。

如果大家希望得到的效果是每一次生成结果完全一致呢？top k取个一。它每次结果都是一样的。啊，所以你如果希望每次升级结果完全一致，不是通过temperature来控制的，是通过top k来控制的。啊，这两个参数是配合来使用的，明白了吧？我们这给个50，就是让你从概率最高的50个结果里面随机的去取啊，随机性为零点七。啊，这个就比较好理解啊。

呃，当然这个talk不能给的太大啊，给的太大的话呢，那个结果会变差，明白了吗？啊，结果会变差。好，然后to pp呢？它是一个核采样数啊，这个是进一步限制模型生成时词汇的选择范围。它会选择一组累积概率达到p的词汇，这个to pp呢？不是直接的排序，它是累积概率啊，

累积概率模型只会从这个概率集合中进行采样。啊，比如说我们这儿给的是零点九，那就意味着模型会在可能性最强的90%的词中。去选择下一个词，进一步生成文本的质量就是这个to pp，我们一般概率建议给高一些，我们一般给的是零点九。啊，零点九啊好，这三个参数非常重要，目前我们后面所用到的所有的文本生成大模型里面啊，你在进行推理使用的时候。啊，它的框架上面都有这些参数，

这个temperature和top top key的一个设置啊，都有这些东西设置，一般框架里面它默认这个top key人家是定死的。我们需要控制这两个参数。啊好，那么最后。这是一个清理空格的啊，清理空格的清理这个空格键的就是这个参数控制文本生成中是否清理分词时引入的一个空格，如果为处。就会把多余的空格给清除掉，如果为FALSE的话呢，就保留原样啊，就这个意思。好，这是主要做一些格式控制的哈，

其实核心就是这三个参数，我们对它做了这个控制之后，现在我们再来生成看一下这个效果。那么理论上来讲，它现在升的效果要比刚刚那个前因不搭后尾的效果要好一些啊。啊，这一次我用的是哭的。那么，这次用扩大的话呢？它会用这个gpu去加载一下啊，用gpu加载一下，所以gpu会往上弹一点点。看到没有？提示我们用哭的啊gpu会弹一点点啊，会跑一下。

好来看一下啊。你好，我是一款语言模型，来自英国的一位资深程序员，他在写程序时用的是linux，我们很熟悉，他在学习语言。这个虽然说相关性不强，但是有点关系啊，毕竟这个模型太小了啊，我们现在这个模型只有400M，并且大家现在可以看一下你每次生成的结果是不一样的。啊，每次生成结果，现在都是随机的，

因为top k我们给它输50啊。咳咳。好，这是讲这个嗯，简单的这个pp tt的一个用法。看到没有？你好，我是一款语言模型，来自英国的一款语言模型，我们现在使用的语言模型可以通过呃语言模型进行解释哈。感觉他说的有点有点那种废话，文学，但最起码人家这个前面跟后面有相关性了，比我们第一次直接去使用它的这个效果是要好一些的啊。当然了，

它肯定达不到我们现在的那些大模型的效果啊，我们那个大模型比较大啊，现在第一节课我们先不玩那么大的，先教大家用这些小模型简单理解一下这个生成模型的一个语，一个用法和原理哈，重点是掌握这个平台的一一个用法哈。好，这是本地调用这个模型啊，本地调用这个模型。咳咳。OK好，那是本地的一个用法啊。啊，然后这是生成模型，接下来我们再给大家介绍另外一款，

介绍另外一款，因为我们前面hang face平台，上面我们有。涉及到一些编程的底层操作的东西，我们需要去讲两个部分，这两个部分就是我们现在讲的这个用的这个GB two啊。它实际上是transformer的第生成器啊！生成器！这下节课我给你们说这个这个东西吧啊，今天我们先说到这简单讲一下吧。就大家得知道一个概念，我们现在的这个大模型，它是基于transformer的transformer，有两个部分构成，有两个部分构成，

一个是。嗯，编码器。编码器编码器叫bert。这个b主要做什么？主要做分类啊，主要做分类应用。它是做分类应用的，另外一个是解码器，解码器是gbt。这个主要做什么？主要做生成。你像我们刚刚给大家体验的这个模型，就是一个生成模型啊，就是生成模型。

呃，我们现在的自然语言大模型核心是基于这个gbt构建出来的啊，但是完整的transformer其实是bert+gbt啊。bert+gbt。bert主要做分类啊，那么我们接下来给大家也介绍一下这个bert啊，看这个bert。好bert一样的啊，我们这个bert还是从那个模式上面去搜一下。啊，好用什么来搜一下啊？我们看一下这个bert。models你直接在这来搜，叫bert base Chinese啊。bird with Chinese.

啊bird base Chinese。嗯嗯，我看一眼啊。这个原始的那个模型排名不高了。原始那个模型排名不高了，这还一下子有11页，我们可能还不好翻啊。因为这个名字太太普通了啊，名字太普通了，其实它上面有一个模型，就直接叫bert base Chinese啊，但是现在雷同的比较多啊，我看这个download。能不能找到呢？啊，

看不到，看不到算了，就它的全称就叫bert base Chinese啊，但是可能得一个一个翻，我们这就不翻了啊，我直接带你们来下载来使用啊。啊，我们来看第三个案例。test零三。啊零三我们看一下这个分类模型。啊，分类模型。呃，它的用法跟刚刚一样啊，我们还是导入模型部分transformers。

transformers in port当然现在这个模型叫bert啊，我们就导入的是这个bert。bert的token letter呃。还有bert。呃，for。sequence.classification啊，就是bert做语句分类的啊，bert做语句分类的。OK，然后再导入这个pipeline啊。啊，再导入pop。好，

前面用法跟这一样，就是我们也是加载这个什么呢？加载模型跟分词器啊，加载模型跟分词器。把这一块就拷贝一下。但是它那个路径就变了。啊，这个路径就变了。呃，这个头改一下啊，这是我们的是bert sequence啊，这个是bert toke na der。这是bert模型，主要做分类用的啊，但是分类的话呢，

我们现在直接去看大家看不到这个效果啊，直接去看大家看到这个效果。好。模型下哦，对这模型先得下载对吧？我们先下一页吧。我们这先来下一页啊。下载我给大家嗯，新建一个吧。哎，算了，我把这个保留一下。我们先把它下一下。呃，这样吧，

我直接在这个里面下了，我就不单独在这儿搞一个下载了，我直接在这里面下下了，我们来用啊，这儿我直接在这儿下。直接在这下，直接在这下，我们这样来写。呃，绝对值下降了一些。model.呃，这就不是model directory啊，直接来下的话呢，我们得去搜这个名字，

它叫做。等一下啊，它叫这个。就这个啊，就叫bert base Chinese啊，bert base Chinese好，这个叫catch directory。还有时候这怎么没提示了呢？拿过来呃catch directory。OK好，这个模型名字叫bert based Chinese啊。好，我们直接给它下载下载到哪里去呢？就下载到这个下载到这个嗯D盘的这个位置啊，下载到我们这个D盘这个位置。

这儿就不给绝对路径了，我们就给一个相对路径，我看一下。给到model这给到给到这个里面。给到这个里面，然后名称就叫做bert base Chinese。啊，给它改一下啊，好先让它来进行下载。啊，就是你直接这样去加载它，就是下载明白了吗？我们再来下一页啊，这来右键run一下。先下载，

等它下下来，我们再来调用啊。这个我放到model下面啊model下面叫bird base Chinese的一个文件夹。这个模型的全称就叫bert base创意者啊，它就在hang face模型里面啊，但是它这个名字匹配，因为前面重名的太多了啊，所以说你直接第一页看不到，你们如果想翻，你可以翻一翻。翻译翻译，它应该排到后面几页了啊，就就全称就是这个啊，全称就是这个名字，因为我们在这儿是可以下载下来的，

你只要是从这儿可以下载下来的模型，它上面都有。好，这个模型也不大啊，也是几百兆。啊，也是几百兆。好，下载结束了啊，我们看一下。下载的这个权重跟刚刚结构是一样的，看到没有点开之后对吧？这个snapshots你看这个文件夹，它就跟刚刚的这个GBA two就有一点点区别啊，我说过了。

有些模型人家是放在两个文件夹里面的，比如说我们刚刚看到这个g bd two，它是放在两个文件夹里面的，然后这个bert base Chinese呢，就放在一个文件夹里面了。看到没有？这个model shift tensors就是它的模型权重config跟刚刚一样啊。啊，这是bert模型啊bert模型。OK哎，它的字典也是二幺幺二八，因为这两个东西用的是同一个字典。啊，这两个东西用的是同一个字典，这是模型的权重，

这是。那这是我们刚刚刚给大家看过的token letter啊，这个token letter。这个统计代码里面编编码的内容就比较多了，因为它是把。呃，这个bird base哪里的？它是把这个中文的那个字典哈也编码进去了。看到没有，然后是编码到这个里面去了啊，所以这个头里面是包含了五个cap字典的啊，这是它的config。这个模型的最大长度就短一些，因为它做文本分类啊，短一些最大长度是512。

这个东西特别注意一下，我们下节课的实操，我们下节课会基于这个项目带着大家来做第一个基于这个模型带着你们来做第一个小的项目啊，第一个小的项目。我们会训练一个这个呃文本的评价系统啊，但是它上面就有一个限制。你最大输入长度是512啊。注意一下一样的，你看这是它的字典啊，所以说这些模型的这个结构字典是非常类似的啊，这两个东西字典是一套啊。啊，这两个东西字典是一套啊，因为你们注意一下这个。这个talking neither啊。

我们刚刚看了个GBA two的token letter，它用的是谁？它用的就是bert的token letter，看到没有啊？用的就是bert啊。好，这是权重，给大家简单看一下权重，下完之后，接下来我们也是教各位来用一下这个分类的啊，分类的。分类的这个本例模型怎么来用？我们来看一下。好把这个就先关掉啊。OK，

模型加载好了之后。模型加载好了之后嗯呢，我们下一步就来创建这个。分类online啊。啊，创建分类pipeline啊。嗯，我我这多说一句话，各位注意一下这种用法跟这种用法是有区别的。啊，这两种都是在加模型，但是你们注意我们这儿加模型的方法不一样，这儿加模型我是从哪儿加的？我是不是从？我是不是从这个里面去加的，

看到没有，所以如果你填的这个地址是个相对地址。它一一定是先要去访问一下网络的，然后看到你本地有缓存才会去缓存加载。而零二里面写的这个绝对路径，我在访问的时候直接访问的是本地模型，它不用去联网。啊，两种是有区别的啊，我们看一下，你可以把这个这个零三的代码改成零二的，你把模型下好之后就可以改了啊，改成绝对路径就行了啊。这个开始就可以去掉，把这个改成一个绝对路径就可以了OK，

但是我这为了区分给你们看一下啊，好接下来我们说一下这个创建分类模型啊，分类模型分类模型做这个pipeline创建的啊。好，我们这叫做classifier。啊，就等于。呃，就等于我们的这个pipeline。好，那么这是一个文本分类啊，所以说它跟刚刚零二里面的文本生成有区别，我们刚刚是text generation，那么现在是叫text。classification啊。

cation嗯。这个东西参数它里面是有介绍的。啊，我觉得它用法里面有介绍啊。看到没有，它用法里面有介绍，看到没有，这里面参数不是我们自己随便乱乱编的啊，它里面填的内容是有介绍的。看到了吗？它所有参数在API里面，点进去可以看得到啊啊，点进去可以看得到啊，让文本生成，我们刚刚是文本的这个分类。

啊文本分类。啊，你如果说懒得写的话，你点开它的API粘贴一下，复制粘贴一下也行，也没问题啊，也没问题。好，然后把模型加进来model=model model=model。呃，还有就是toke na der啊，就等于toke na der啊，toke na der，然后是我们的device啊，这里面我就直接用这个库导了。

大家拿到代码时候跑之前看一下你的环境，再提一下啊，看一下你的环境，你是CPU就直接换成CPU啊。好，那么下一步我们就可以进行分类啊。进行文本分类。啊，进行文本分类。它是做文本分类用的。啊调用这个class c class fair传入一句话。比如你好。我还是刚刚那句话，我是一款。语言模型啊，

我们看一下它现在是怎么输出的啊？我们print一下它这个result。print这个result来看一下。它这会会这一次会比较慢一点。呃，为什么它现在会比较慢一点呢？我刚刚说过了，这个代码现在这个调用逻辑是它先要去访问。你的这个什么呢？谷歌云盘上面这个模型的路径地址。啊，如果你网络现在不不通的情况下呢？它这有可能会报错，它会提示你这个连接超时啊，连接超时因为。

你们记住啊hang这个平台上面有一个特点，就是如果你是以这种方式来加载模型的，不管你本地有没有缓存，它一定先要访问hand face的官网。然后访问到官网之后再去验证你本地有没有，有的话就不下载，没有的话就下载。而真正的离线电容是这种方法。那我再说一次加载离线的路径，直接把模型加上去，它就不用去联网访问了啊好，所以你们到时候得特别注意一下。你们拿到这个代码之后，你可以因为我这给你们一起权重了哈，你就直接把这个权重路径给它拷贝一下啊，

拷贝成绝对路径。把这个cache director给它删了，它调起来就要快一些啊。好，我们来看一下它这输出的结果。呃，大家可以看到啊，这个分类模型，它现在给了我们这么一个结果。它返回的是个列表，列表名的范围是一个json字符串。里面呢，给了一个label。叫label杠零给了一个得分零点六七一九，这是个什么意思呢？

这是个什么意思呢？不是做分类吗？对吧？好我们这简单给你们讲一下分类啊。呃，我们打印下这个模型。我把这个模型打一下啊print一下这个model。我们借助这个模型的结构，给大家简单说一下先，今天晚上我们先对这个模型有一个基本的了解，然后分类模型，它跟生成模型最大的区别就在于。文本生成模型，不管有没有做过训练，就是我们拿到手之后啊，

我们自己哪怕不训练的情况下，你都可以看到它，都可以生成一些这个文本出来。对吧，就是我们很直观的可以看到它做文本的一个续写，虽然说这个续写的质量不高，但是我们可以看到它可以做续写的，如果说。听清楚，如果你希望这个模型，比如说拿生成模型来讲，我们希望这个模型生成的内容是我想要的内容，比如说我让它生成古诗词。可不可以？当然可以，

我们得做什么得做训练啊？这是我们后面的第二个小项目啊，到时候我会带着大家手把手的从数据开始。就借助于这个g bd two，我们来训练一款自己的这个文本生成模型啊，你得做训练，那么同样道理分类模型，它也得做训练。啊，分类模型，它也得做训练，它不做训练的情况下呢，它其实没有标签，它只能够给你一个得分。我们来看一下这个模型，

打印出来之后。bert模型啊，它分为三个部分。三个核心的部分，第一个叫做。嗯，它的这个头部其实这个头部里面放的是embedding模型。bert里面这个第一个部分叫embedding模型。embedding模型干嘛的编码用的？今天先听概念哈，我们下节课会带你们来实操啊，编码用的编码什么玩意儿呢？就是这个模型的作用呢？它是将文本。转成模型可输入的向量。

啊，这记住啊。这个结构是做的文本转向量的过程，拿到向量之后呢，其实它不是我们真正的这个AI的特征提取模型。啊，它只是把文本转成了词向量。然后真正的特征提取模型叫encoder模型，就是我们刚刚所所提到的这个编码模型，它主要做特征提取啊，编码模型编码模型的作用就是将。这个向量呢？代表什么意思？进行特征的分析和理解就是由这个encoder来控制的。啊，

就由这个encoder编码模型来做处理的这块东西做的事呢，就是将词向量。词向量做什么呢？做特征的理解和提取，我们把它我们一般在AI里面把它叫特征提取。他要AI学会理解你这些文本代表什么意思，想表达什么含义啊，就是由这个encoder核心进行处理的，叫特征提取。啊特征提取那么提取完了特征之后，他理解了这个文本的含义之后，他就得干活了，活是由谁干的呢？这个叫池化层，这个可以不管啊，

这个可以不管，这个池化层的作用是保持模型的，这个适用性的，还有这个drop out的作用是。防止模型做过拟合的哈干活的，其实是它叫分类层。啊，分类层像这个class fair，它是做分类的。这个class f做分类的你，比如说你看这个模型，它默认的这个分类是二，它就作为二分类啊，它就作为二分类。二分类那么沿位置是这个模型整体输入结果就只有两个结果啊，

就是两个类别明白了吧啊，两个类别。然后它现在给我们输出的这个意思是什么？它这输出的是最最高的这个类别是零点七五啊，零点七五，所以模型本质上只能输出概率。他没法去呃，按照我们想的那个结果，他现在还做不到啊，如果说打个比方，我给你们看一下。文本分类的一个应用案例，大家就明白这个文本分类的价值在哪了。我们看一个现成的应用啊，这个应用我们下节课会带你们来，

自己自己做一下啊。百度有一个AI开放平台。它这里面有个开放能力。有一个文本文字的识别，它有一个情感。分析的东西。语言与知识啊，应该在这个里面。我看一下啊，还有个情感分析。机器翻译。情感倾向分析。这就是一个文本，文本分类的一个案例啊。m测试一下啊，

测试一下。啊，这得登一下是吧？他这个案例用得登一下，没事，登一下，我们登一下吧。嗯，灯一下吧，马上啊。我这登一下，登一下给你们演示一下啊，大家对它有一个形形象的，这个理解会会更会更好啊，因为我们今天只是模型部分，

还没有做到应用的下节课会带着大家来做这个应用。那我们可以看一下这个东西，然后做完之后什么样子啊？什么是沃尔沃？咳咳咳。好，我登录一下啊，登录一下，带你们来玩一下。好比如说啊，什么叫文本分类呢？比如说我们说一句话，美女你好。啊，可以加个微信吗？

v好，你看啊。大家觉得我我们这句话它表达的这个情感倾向是正向的还是负向的，是正向的对吧？你看人家这个情感正向是79%。就是你有有一种期待的这个感觉，在里面吗？好，然后后面再来一句。比如说人家回复了，不可以。这个情感倾向是不是一下就有79%就掉到31%了？能理解吧，就是做文本分类啊，文本分类，

你看人家这个做的也是二分类。但是它分类的结果，其实这就是概率值理解没有啊，概率值一般的预值，这可能设为50%。啊设为50%啊，就是两个分类嘛，如果你低于50%哎，我就给你输出这个正向情感，你高于5%呃，这个高于50%就是个正向情感，低于50%的话就是个什么负负向情感，就这个意思啊，就是当然它这给的是情感的正向值。啊，

正向值。啊，所以模型始终分输出的是个概率啊，模型始终。呃，你们说那就不用不用那个嘛，就可以啊，可以啊，你说个可以，它不就是百分96了吗？对吧？你们倒是可以自己玩一玩啊，这个百度AI的开放平台上面。这个自然语义上面有很有，就这块自然语义的东西啊，

这个情感啊，评论观点抽取啊，对话情绪识别可以去玩一玩哈。啊，玩一玩就效果刚刚给你们看过了，就是就是哎啊，哪去了就就这个啊，就这个啊，我们做的第一个应用呢，就是到时候我会带着带着大家基于这个bert。就这个word，我们到时候自己做一个数据做的比它有价值哈，它这个东西其实价值不高啊，价值不高，我们下节课就带着大家来实操做第一个案例。

第一个案例，我们这个价值是做什么东西呢？我们主要做现在的这个购物平台或者一些什么电商平台的一些评论。评论的这个情感倾向分析，就看你是个好评还是个差评？啊，就是你看你的评价是好评还是差评，让AI自动去识别这个识别的精度，我们可以做的很高啊，做的很高好，那么当然我们用的模型就是基于这个b模型来做啊，就是我今晚。带着各位来下的这个模型来做的，明白了吧？但这个模型大家现在可以看到你看，

比如说我输入这么一段话，它其实没有办法直接给我们想要的，结果它只是给了一个得分，为什么它现在给不了呢？因为。我们没有去设计它的这个分类层。分类层得自己设计这个东西哈。我们自己就是作为应用开发是个什么什么意思？同学们听清楚应用开发模型，它是现成的，它不需要你去写。你像我们今晚戴尔拉主要是了解这个模型，两两款模型的一个基本的一个获取和下载，对吧？怎么来用一用的？

一个是生成模型，一个是这个什么呢？分类模型，但是大家会发现这个分类模型和这个生成模型，你直接下下来，它的效果是不行的。打个比方，你比如这个GB two啊，我想让它生成古诗词，它现在做不到，对吧？它现在生成这个普白话文的效果都很差，不要说生成古诗词了。那如果我现在就有个需求，我让你给我生成股市怎么办？

我们得自己做应用开发，能理解我意思吧，这就是应用开发。啊叫硬开发就是我们得根据我们自己的这个业务逻辑需求去做落地，所以我再说一遍，我们不用去开发这个模型，本身模型本本身是别人开发好的。我们的重点是要掌握这个应用的一个开发流程啊，包括这个分类啊分类，那么我们下节课先带着各位来玩这个分类分类，我们做中文的这个商品评价分析。啊，评论区的这种分析情感情感倾向分析。嗯，我们会从数据集开始，

带着各位基于这个bert base Chinese来微调一个自己的这个离线大模型，那么有了这个大模型之后，你就可以做评论区的这种评价分析了。这个东西还是很有价值啊。啊，因为这个东西我们本身自己就在用啊，我自己本身就在用嗯AI这个东西，现在最接近于挣钱落地的方向呢，就是跟。现在的比如说什么多媒体平台呀，电商平台呀，对吧？去结合那么你像我们现在的这种。呃，自媒体平台啊，

自媒体平台里面有一个非常重要的数据，就是评论区的这种情感倾倾向分析评论区的需求分析，对吧？那么，那些模型都需要做定制化了啊，我们下节课的第一个案例就教大家怎么基于这个模型，怎么从数据集开始啊来训练我们自己的这个模型部分啊？哦，我说一下我们的这个模型，目前这这个实验就是。嗯，评论分类模型的实验，这个项目还有文本生成这个项目，因为模型本身不大。所以各位现在不需要去准备。

太好的服务器啊，服务器什么时候用，我到时候会给你们说，不着急，这两个模型基本上。基本上呢？嗯，你有好一点的CPU都可以训练，能懂我意思吧？你有好一点的CPU都可以训练啊？所以说大家不用去着急，那个电脑的问题，你们下去之后把这个环境搞好啊，在下节课就是周五的时候，周五之前啊，

最好把这个环境搞好。我们下课，你们到时候就可以自己来训练，第一个模型了好吧？OK啊，好那么这个。hang face的基本的第一节课的用法，我们就给大家先说到这啊，今天我们就核心掌握两款模型，一个是这个birch的下载和基本调用。另外就是这个GB two的基本调用和这个下载啊，离线模型这一块是重点API这个东西玩一下就行了，那个东西不重要，因为价值不高啊，价值不高。

呃，这个模型可以不下载啊，因为我到时候把模型会一起发给你们，就是整个项目加模型会一起发给你们哈，你们把环境打好之后。可以先练上手，练一练跑一跑啊，跑一跑，我们下节课从数据集开始教大家先用第一个bert模型来做，我们第一个案例啊。呃，数据一不着急啊，数据一不着急，数据一上面我们会教你们去做啊，我们下节课教你们去做啊。

好，行吧，我们今晚的课程内容就先到这里啊。
